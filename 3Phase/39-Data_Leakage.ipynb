{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Learning Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- avoid letting information about test sets get into the training of models\n",
    "- use best practices for building non-leaky workflows\n",
    "- repair leaky workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have encountered the idea of splitting our data into two, *training* our model on one bit and then *testing* it on the other.\n",
    "\n",
    "The goal is to have an unbiased assessment of our model, and so we want to make sure that nothing about our test data sneaks into the training run of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## A Mistake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now consider the following workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019908 -0.017646   151.0  \n",
       "1 -0.039493 -0.068330 -0.092204    75.0  \n",
       "2 -0.002592  0.002864 -0.025930   141.0  \n",
       "3  0.034309  0.022692 -0.009362   206.0  \n",
       "4 -0.002592 -0.031991 -0.046641   135.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_diabetes()\n",
    "\n",
    "print(data.DESCR)\n",
    "\n",
    "df = pd.concat([pd.DataFrame(data.data, columns=data.feature_names),\n",
    "               pd.Series(data.target, name='target')], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Scale and run a regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Well we fit the model only to our training data. Looks like we've done everything right, right?\n",
    "\n",
    "It's important to understand that the answer here is a resounding \"NO\". It's true that we didn't directly fit our model to our test data. But the trouble is that we fit our scaler **to the whole dataset**. That is, records in the test data are contributing to calculations of column means and standard deviations, and so, surreptitiously, information about our test set is sneaking into the training run of the model after all!\n",
    "\n",
    "To correct our mistake, we'll make sure to perform our train-test split **first**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Code\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_sc = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sc, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.27107279 -11.5103763   25.30316447  18.14921047 -43.68812386\n",
      "  24.17505729   5.56228784  12.81809837  33.09612684   1.25207795] 151.66516982689885\n"
     ]
    }
   ],
   "source": [
    "#leakage\n",
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, random_state=42)\n",
    "\n",
    "ss2 = StandardScaler()\n",
    "\n",
    "X_train_sc2 = ss2.fit_transform(X_train2)\n",
    "#just transform the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LinearRegression()\n",
    "\n",
    "lr2.fit(X_train_sc2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.21493322 -11.51452473  25.07685109  18.24943843 -44.14403151\n",
      "  24.5135485    5.4971345   13.00640779  33.3797142    1.24791796] 154.34441087613294\n"
     ]
    }
   ],
   "source": [
    "print(lr2.coef_,lr2.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that our model coefficients are slightly different from what they were before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Error Comparison\n",
    "\n",
    "It's worth pointing out that, **for linear models**, there is **no** difference in modeling error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss2 = StandardScaler().fit(X_train2)\n",
    "X_train2_scld = ss2.transform(X_train2)\n",
    "X_test2_scld = ss2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test RMSE for this model is 72.75.\n"
     ]
    }
   ],
   "source": [
    "y_test_hat2 = lr.predict(X_test2)\n",
    "mse = mean_squared_error(y_test2, y_test_hat2)\n",
    "print(f\"Our test RMSE for this model is {round(np.sqrt(mse), 2)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test RMSE for this model is 72.75.\n"
     ]
    }
   ],
   "source": [
    "y_test2_hat = lr2.predict(X_test2_scld)\n",
    "mse = mean_squared_error(y_test2, y_test_hat2)\n",
    "print(f\"Our test RMSE for this model is {round(np.sqrt(mse), 2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This will **not** be true for other sorts of models that use different loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In general all preprocessing steps are subject to the same dangers here. Consider the preprocessing step of one-hot-encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gun_poll = pd.read_csv('data/guns-polls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Pollster</th>\n",
       "      <th>Population</th>\n",
       "      <th>Support</th>\n",
       "      <th>Republican Support</th>\n",
       "      <th>Democratic Support</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age-21</td>\n",
       "      <td>2/20/18</td>\n",
       "      <td>2/23/18</td>\n",
       "      <td>CNN/SSRS</td>\n",
       "      <td>Registered Voters</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>86</td>\n",
       "      <td>http://cdn.cnn.com/cnn/2018/images/02/25/rel3a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age-21</td>\n",
       "      <td>2/27/18</td>\n",
       "      <td>2/28/18</td>\n",
       "      <td>NPR/Ipsos</td>\n",
       "      <td>Adults</td>\n",
       "      <td>82</td>\n",
       "      <td>72</td>\n",
       "      <td>92</td>\n",
       "      <td>https://www.ipsos.com/en-us/npripsos-poll-majo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age-21</td>\n",
       "      <td>3/1/18</td>\n",
       "      <td>3/4/18</td>\n",
       "      <td>Rasmussen</td>\n",
       "      <td>Adults</td>\n",
       "      <td>67</td>\n",
       "      <td>59</td>\n",
       "      <td>76</td>\n",
       "      <td>http://www.rasmussenreports.com/public_content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age-21</td>\n",
       "      <td>2/22/18</td>\n",
       "      <td>2/26/18</td>\n",
       "      <td>Harris Interactive</td>\n",
       "      <td>Registered Voters</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>92</td>\n",
       "      <td>http://thehill.com/opinion/civil-rights/375993...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age-21</td>\n",
       "      <td>3/3/18</td>\n",
       "      <td>3/5/18</td>\n",
       "      <td>Quinnipiac</td>\n",
       "      <td>Registered Voters</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>93</td>\n",
       "      <td>https://poll.qu.edu/national/release-detail?Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Question    Start      End            Pollster         Population  Support  \\\n",
       "0   age-21  2/20/18  2/23/18            CNN/SSRS  Registered Voters       72   \n",
       "1   age-21  2/27/18  2/28/18           NPR/Ipsos             Adults       82   \n",
       "2   age-21   3/1/18   3/4/18           Rasmussen             Adults       67   \n",
       "3   age-21  2/22/18  2/26/18  Harris Interactive  Registered Voters       84   \n",
       "4   age-21   3/3/18   3/5/18          Quinnipiac  Registered Voters       78   \n",
       "\n",
       "   Republican Support  Democratic Support  \\\n",
       "0                  61                  86   \n",
       "1                  72                  92   \n",
       "2                  59                  76   \n",
       "3                  77                  92   \n",
       "4                  63                  93   \n",
       "\n",
       "                                                 URL  \n",
       "0  http://cdn.cnn.com/cnn/2018/images/02/25/rel3a...  \n",
       "1  https://www.ipsos.com/en-us/npripsos-poll-majo...  \n",
       "2  http://www.rasmussenreports.com/public_content...  \n",
       "3  http://thehill.com/opinion/civil-rights/375993...  \n",
       "4  https://poll.qu.edu/national/release-detail?Re...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gun_poll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YouGov                 12\n",
       "Morning Consult        11\n",
       "Quinnipiac              8\n",
       "NPR/Ipsos               7\n",
       "CNN/SSRS                5\n",
       "CBS News                4\n",
       "Suffolk                 2\n",
       "Rasmussen               2\n",
       "ABC/Washington Post     1\n",
       "Harris Interactive      1\n",
       "YouGov/Huffpost         1\n",
       "Harvard/Harris          1\n",
       "Marist                  1\n",
       "SurveyMonkey            1\n",
       "Name: Pollster, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gun_poll['Pollster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now if I were to fit a one-hot encoder to the whole `Pollster` column here, the encoder would learn all the categories. But I need to prepare myself for the real-world possibility that unfamiliar categories may show up in future records. Let's explore this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# First I'll do a split\n",
    "X_train, X_test = train_test_split(gun_poll, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's suppose now that I fit a `OneHotEncoder` to the `Pollster` column in my training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fit an encoder to the `Pollster` column of the training data and then check to see which categories are represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code\n",
    "\n",
    "to_be_dummied = X_train[['Pollster']]\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "ohe.fit(to_be_dummied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_ABC/Washington Post', 'x0_CBS News', 'x0_CNN/SSRS',\n",
       "       'x0_Marist', 'x0_Morning Consult', 'x0_NPR/Ipsos', 'x0_Quinnipiac',\n",
       "       'x0_Rasmussen', 'x0_Suffolk', 'x0_YouGov', 'x0_YouGov/Huffpost'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So what categories do we have?\n",
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll want to transform both train and test after we've fitted the encoder to the train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<42x11 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 42 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_to_be_dummied = X_test[['Pollster']]\n",
    "\n",
    "ohe.transform(to_be_dummied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['SurveyMonkey', 'Harris Interactive', 'Harvard/Harris'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-28aefb39d043>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_to_be_dummied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;31m# validation of X happens in _check_X called by _transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mX_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_int\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m    122\u001b[0m                     msg = (\"Found unknown categories {0} in column {1}\"\n\u001b[0;32m    123\u001b[0m                            \" during transform\".format(diff, i))\n\u001b[1;32m--> 124\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;31m# Set the problematic rows to an acceptable value and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['SurveyMonkey', 'Harris Interactive', 'Harvard/Harris'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "ohe.transform(test_to_be_dummied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are categories in the testing data that don't appear in the training data! What should \n",
    "we do about that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Strategy 1**: Divide up the categories proportionally when we do our train_test_split. If we're using `sklearn`'s tool, that means taking advantage of the `stratify` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-de303dbf4df1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m new_X_train, new_X_test = train_test_split(gun_poll,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                            \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgun_poll\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pollster'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                            random_state=42)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2150\u001b[0m                      random_state=random_state)\n\u001b[0;32m   2151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2152\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1339\u001b[0m         \"\"\"\n\u001b[0;32m   1340\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1341\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1342\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1666\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1668\u001b[1;33m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[0;32m   1669\u001b[0m                              \u001b[1;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1670\u001b[0m                              \u001b[1;34m\" number of groups for any class cannot\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "new_X_train, new_X_test = train_test_split(gun_poll,\n",
    "                                           stratify=gun_poll['Pollster'],\n",
    "                                           random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unfortunately, in this case, we can't use this since some categories have only a single member."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Strategy 2**: Drop the categories with very few representatives.\n",
    "\n",
    "In the present case, let's try dropping the single-member categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Code\n",
    "\n",
    "vc = gun_poll['Pollster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YouGov                 12\n",
       "Morning Consult        11\n",
       "Quinnipiac              8\n",
       "NPR/Ipsos               7\n",
       "CNN/SSRS                5\n",
       "CBS News                4\n",
       "Suffolk                 2\n",
       "Rasmussen               2\n",
       "ABC/Washington Post     1\n",
       "Harris Interactive      1\n",
       "YouGov/Huffpost         1\n",
       "Harvard/Harris          1\n",
       "Marist                  1\n",
       "SurveyMonkey            1\n",
       "Name: Pollster, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_1 = vc[vc==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bad_cols = vc_1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ABC/Washington Post', 'Harris Interactive', 'YouGov/Huffpost',\n",
       "       'Harvard/Harris', 'Marist', 'SurveyMonkey'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove bad columns\n",
    "gun_poll['Pollster'] = gun_poll['Pollster'].map(lambda x: np.nan if x in bad_cols else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_poll.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YouGov             12\n",
       "Morning Consult    11\n",
       "Quinnipiac          8\n",
       "NPR/Ipsos           7\n",
       "CNN/SSRS            5\n",
       "CBS News            4\n",
       "Suffolk             2\n",
       "Rasmussen           2\n",
       "Name: Pollster, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sniff test!\n",
    "gun_poll['Pollster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We could now split this carefully so that new categories don't show up in the testing data. In fact, now we can try the stratified split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train3, X_test3 = train_test_split(gun_poll,\n",
    "                                     stratify=gun_poll['Pollster'],\n",
    "                                     test_size=0.3,\n",
    "                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YouGov             8\n",
       "Morning Consult    8\n",
       "Quinnipiac         6\n",
       "NPR/Ipsos          5\n",
       "CBS News           3\n",
       "CNN/SSRS           3\n",
       "Suffolk            1\n",
       "Rasmussen          1\n",
       "Name: Pollster, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sniff Test\n",
    "X_train3.Pollster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YouGov             4\n",
       "Morning Consult    3\n",
       "Quinnipiac         2\n",
       "NPR/Ipsos          2\n",
       "CNN/SSRS           2\n",
       "Suffolk            1\n",
       "Rasmussen          1\n",
       "CBS News           1\n",
       "Name: Pollster, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test3.Pollster.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now every category that appears in the test data appears also in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Strategy 3**: Adjust the settings on the one-hot-encoder.\n",
    "\n",
    "For `sklearn`'s tool, we'll tweak the `handle_unknown` parameter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exericse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fit a new encoder to our training data column that won't break when we try to use it to transform the test data. And then use the encoder to transform both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15x11 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe2 = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe2.fit(to_be_dummied)\n",
    "test_to_be_dummied = X_test[['Pollster']]\n",
    "ohe2.transform(to_be_dummied)\n",
    "ohe2.transform(test_to_be_dummied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_ABC/Washington Post', 'x0_CBS News', 'x0_CNN/SSRS',\n",
       "       'x0_Marist', 'x0_Morning Consult', 'x0_NPR/Ipsos', 'x0_Quinnipiac',\n",
       "       'x0_Rasmussen', 'x0_Suffolk', 'x0_YouGov', 'x0_YouGov/Huffpost'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_be_dummied.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Leakage into Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If we employ cross-validation, then our training data points will be serving both for training and for validation. So there's a sense in which we can't help but let some information about our validation data sneak into the model.\n",
    "\n",
    "But strictly speaking, cross-validation means building *multiple* models, and we still want each to be blind to its validation set.\n",
    "\n",
    "The dangers of data leakage, therefore, are still very much real in the case of validation data. And they are often more subtle as well. Consider the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mse = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using our scaled training data\n",
    "\n",
    "cv_results = cross_validate(estimator=LinearRegression(),\n",
    "                X=X_train2_scld,\n",
    "                y=y_train2,\n",
    "                scoring=mse,\n",
    "                return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7680116279314739,\n",
       " -0.05303892863219472,\n",
       " 2.5202065136668326,\n",
       " 3.724688517936679,\n",
       " 4.554018949497544]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at model coefficients on the first predictor\n",
    "\n",
    "[model.coef_[0] for model in cv_results['estimator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We've built five models here, and none of them saw any points from the test data, so we have no leaks, right?\n",
    "\n",
    "Wrong! We fit the `StandardScaler` to the whole training set, which means that information about *every* fold will affect every cross-validation. A better practice here would be to split our data into its cross-validation folds *first*. Then we can fit the scaler to only the training folds for each cross-validation.\n",
    "\n",
    "Of course, the more preprocessing steps we have, the more tedious it becomes to do this work! For such tasks it is often greatly beneficial to take advantage of `sklearn`'s `Pipeline`s, which we'll have more to say about later.\n",
    "\n",
    "For now, let's see if we can fix our leaky cross-validation scorer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Go back to `X_train2` and do the following:\n",
    "\n",
    "- Split it into five validation folds (Use `KFold()`).\n",
    "- For each split:\n",
    "- (i) fit a `StandardScaler` to the four-fold chunk and transform all data points with it.\n",
    "- (ii) fit a `LinearRegression` to the four-fold chunk and print out the value of the first coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Code\n",
    "for train_ind, val_ind in Kfold(random_state = 42).split(X_train2):\n",
    "    \n",
    "    train = X_train2.loc[train_ind, :]\n",
    "    val = X_train2.loc[val_ind, :]\n",
    "    \n",
    "    target_train = y_train[train_ind]\n",
    "    target_val = y_train[val_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### A Contrived But Illustrative Example\n",
    "\n",
    "This is only a slight difference in coefficients, but for other datasets the difference can be great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fake_preds = np.array([6, 5, 2, 250, 300]).reshape(-1, 1)\n",
    "fake_target = np.array([25, 30, 12, 400, 420]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.hstack((fake_preds, fake_target)),\n",
    "                 columns=['pred', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "small_train = df[['pred']][:3]\n",
    "small_val = df[['pred']][3:]\n",
    "small_train_y = df['target'][:3]\n",
    "small_val_y = df['target'][3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Scaling the whole dataset\n",
    "\n",
    "ss = StandardScaler().fit(df[['pred']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_tr = ss.transform(small_train)\n",
    "X_va = ss.transform(small_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_tr, small_train_y)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "X = np.linspace(0, 310, 600)\n",
    "y = lr.coef_ * X + lr.intercept_\n",
    "\n",
    "ax.scatter(df['pred'], df['target'])\n",
    "ax.plot(X, y)\n",
    "ax.set_title(f\"\"\"The best-fit line when scaling the whole dataset is\n",
    "    {round(lr.coef_[0])}X + {round(lr.intercept_)}\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Splitting before scaling\n",
    "\n",
    "ss2 = StandardScaler().fit(small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_tr2 = ss2.transform(small_train)\n",
    "X_va2 = ss2.transform(small_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr2 = LinearRegression().fit(X_tr2, small_train_y)\n",
    "lr2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "X = np.linspace(0, 310, 600)\n",
    "y = lr2.coef_ * X + lr2.intercept_\n",
    "\n",
    "ax.scatter(df['pred'], df['target'])\n",
    "ax.plot(X, y)\n",
    "ax.set_title(f\"\"\"The best-fit line when scaling after splitting is\n",
    "    {round(lr2.coef_[0])}X + {round(lr2.intercept_)}\"\"\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
