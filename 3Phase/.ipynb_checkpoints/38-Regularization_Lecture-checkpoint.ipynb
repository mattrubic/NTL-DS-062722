{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#When-a-Good-Model-Goes-Bad\" data-toc-modified-id=\"When-a-Good-Model-Goes-Bad-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>When a Good Model Goes Bad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bias-Variance-Tradeoff\" data-toc-modified-id=\"Bias-Variance-Tradeoff-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Bias-Variance Tradeoff</a></span><ul class=\"toc-item\"><li><span><a href=\"#Underfitting\" data-toc-modified-id=\"Underfitting-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Underfitting</a></span></li><li><span><a href=\"#Overfitting\" data-toc-modified-id=\"Overfitting-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Overfitting</a></span></li></ul></li><li><span><a href=\"#How-Do-We-Identify-a-Bad-Model?-üïµÔ∏è\" data-toc-modified-id=\"How-Do-We-Identify-a-Bad-Model?-üïµÔ∏è-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>How Do We Identify a Bad Model? üïµÔ∏è</a></span><ul class=\"toc-item\"><li><span><a href=\"#Solution---Model-Validation\" data-toc-modified-id=\"Solution---Model-Validation-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Solution - Model Validation</a></span></li><li><span><a href=\"#Steps:\" data-toc-modified-id=\"Steps:-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Steps:</a></span></li><li><span><a href=\"#The-Power-of-the-Validation-Set\" data-toc-modified-id=\"The-Power-of-the-Validation-Set-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>The Power of the Validation Set</a></span><ul class=\"toc-item\"><li><span><a href=\"#From-Validation-to-Cross-Validation\" data-toc-modified-id=\"From-Validation-to-Cross-Validation-2.2.3.1\"><span class=\"toc-item-num\">2.2.3.1&nbsp;&nbsp;</span>From Validation to Cross-Validation</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Preventing-Overfitting---Regularization\" data-toc-modified-id=\"Preventing-Overfitting---Regularization-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preventing Overfitting - Regularization</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Strategy-Behind-Ridge-/-Lasso-/-Elastic-Net\" data-toc-modified-id=\"The-Strategy-Behind-Ridge-/-Lasso-/-Elastic-Net-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>The Strategy Behind Ridge / Lasso / Elastic Net</a></span></li><li><span><a href=\"#Ridge-and-Lasso-Regression\" data-toc-modified-id=\"Ridge-and-Lasso-Regression-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Ridge and Lasso Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Lasso:-L1-Regularization---Absolute-Value\" data-toc-modified-id=\"Lasso:-L1-Regularization---Absolute-Value-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Lasso: L1 Regularization - Absolute Value</a></span></li><li><span><a href=\"#Ridge:-L2-Regularization---Squared-Value\" data-toc-modified-id=\"Ridge:-L2-Regularization---Squared-Value-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Ridge: L2 Regularization - Squared Value</a></span></li><li><span><a href=\"#ü§î-Which-Do-I-Use?\" data-toc-modified-id=\"ü§î-Which-Do-I-Use?-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>ü§î Which Do I Use?</a></span></li><li><span><a href=\"#The-Best-of-Both-Worlds:-Elastic-Net\" data-toc-modified-id=\"The-Best-of-Both-Worlds:-Elastic-Net-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>The Best of Both Worlds: Elastic Net</a></span></li></ul></li><li><span><a href=\"#Code-it-Out!\" data-toc-modified-id=\"Code-it-Out!-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Code it Out!</a></span><ul class=\"toc-item\"><li><span><a href=\"#Producing-an-Overfit-Model\" data-toc-modified-id=\"Producing-an-Overfit-Model-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Producing an Overfit Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-Test-Split\" data-toc-modified-id=\"Train-Test-Split-3.3.1.1\"><span class=\"toc-item-num\">3.3.1.1&nbsp;&nbsp;</span>Train-Test Split</a></span></li><li><span><a href=\"#Dummy!\" data-toc-modified-id=\"Dummy!-3.3.1.2\"><span class=\"toc-item-num\">3.3.1.2&nbsp;&nbsp;</span>Dummy!</a></span></li><li><span><a href=\"#First-simple-model\" data-toc-modified-id=\"First-simple-model-3.3.1.3\"><span class=\"toc-item-num\">3.3.1.3&nbsp;&nbsp;</span>First simple model</a></span></li><li><span><a href=\"#Add-Polynomial-Features\" data-toc-modified-id=\"Add-Polynomial-Features-3.3.1.4\"><span class=\"toc-item-num\">3.3.1.4&nbsp;&nbsp;</span>Add Polynomial Features</a></span></li></ul></li><li><span><a href=\"#Ridge-(L2)-Regression\" data-toc-modified-id=\"Ridge-(L2)-Regression-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Ridge (L2) Regression</a></span></li><li><span><a href=\"#Optimizing-the-Regularization-Hyperparameter\" data-toc-modified-id=\"Optimizing-the-Regularization-Hyperparameter-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Optimizing the Regularization Hyperparameter</a></span><ul class=\"toc-item\"><li><span><a href=\"#Observation\" data-toc-modified-id=\"Observation-3.3.3.1\"><span class=\"toc-item-num\">3.3.3.1&nbsp;&nbsp;</span>Observation</a></span></li><li><span><a href=\"#Cross-Validation\" data-toc-modified-id=\"Cross-Validation-3.3.3.2\"><span class=\"toc-item-num\">3.3.3.2&nbsp;&nbsp;</span>Cross-Validation</a></span></li></ul></li><li><span><a href=\"#LEVEL-UP---Elastic-Net!\" data-toc-modified-id=\"LEVEL-UP---Elastic-Net!-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>LEVEL UP - Elastic Net!</a></span><ul class=\"toc-item\"><li><span><a href=\"#Note-on-ElasticNet()\" data-toc-modified-id=\"Note-on-ElasticNet()-3.3.4.1\"><span class=\"toc-item-num\">3.3.4.1&nbsp;&nbsp;</span>Note on <code>ElasticNet()</code></a></span></li><li><span><a href=\"#Fitting-Regularized-Models-with-Cross-Validation\" data-toc-modified-id=\"Fitting-Regularized-Models-with-Cross-Validation-3.3.4.2\"><span class=\"toc-item-num\">3.3.4.2&nbsp;&nbsp;</span>Fitting Regularized Models with Cross-Validation</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression,\\\n",
    "LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split, KFold,\\\n",
    "cross_val_score, cross_validate, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Explain the notion of \"validation data\"\n",
    "- Use the algorithm of cross-validation (with `sklearn`)\n",
    "- Explain the concept of regularization\n",
    "- Use Lasso and Ridge regularization in model design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One of the goals of a machine learning project is to make models which are highly predictive.\n",
    "If the model fails to generalize to unseen data then the model is bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# When a Good Model Goes Bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> One of the goals of a machine learning project is to make models which are highly predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Adding complexity to a model can find patterns to help make better predictions! \n",
    "\n",
    "But too much complexity can lead to the model finding patterns in the noise..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![Overfitting Model](images/overfitting_model_meme.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    ">So how do we know when our model is ~~a conspiracy theorist~~ overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. High bias\n",
    "    1. Systematic error in predictions\n",
    "    2. Bias is about the strength of assumptions the model makes\n",
    "    3. Underfit models tend to have high bias\n",
    "2. High variance\n",
    "    1. The model is highly sensitive to changes in the data\n",
    "    2. Overfit models tend to have low bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/bias_vs_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Aside: Example of high bias and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "High bias is easy to wrap one's mind around: Imagine pulling three red balls from an urn that has hundreds of balls of all colors in a uniform distribution. Then my sample is a terrible representative of the whole population. If I were to build a model by extrapolating from my sample, that model would predict that _every_ ball produced would be red! That is, this model would be incredibly biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "High variance is a little bit harder to visualize, but it's basically the \"opposite\" of this. Imagine that the population of balls in the urn is mostly red, but also that there are a few balls of other colors floating around. Now imagine that our sample comprises a few balls, none of which is red. In this case, we've essentially picked up on the \"noise\", rather than the \"signal\". If I were to build a model by extrapolating from my sample, that model would be needlessly complex. It might predict that balls drawn before noon will be orange and that balls drawn after 8pm will be green, when the reality is that a simple model that predicted 'red' for all balls would be a superior model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The important idea here is that there is a *trade-off*: If we have too few data in our sample (training set), or too few predictors, we run the risk of high *bias*, i.e. an underfit model. On the other hand, if we have too many predictors (especially ones that are collinear), we run the risk of high *variance*, i.e. an overfit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Here](https://en.wikipedia.org/wiki/Overfitting#/media/File:Overfitting.svg) is a nice illustration of the difficulty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Underfit models fail to capture all of the information in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* low complexity --> high bias, low variance\n",
    "* training error: large\n",
    "* testing error: large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Overfit models fit to the noise in the data and fail to generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* high complexity --> low bias, high variance\n",
    "* training error: low\n",
    "* testing error: large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/bias-variance-table.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## How Do We Identify a Bad Model? üïµÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Solution - Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Generally speaking we want to take more precautions than using just a test and train split. After all, we're still imagining building just one model on the training set and then crossing our fingers for its performance on the test set.\n",
    "\n",
    "Data scientists often distinguish *three* subsets of data: **training, validation (dev), and testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Roughly:\n",
    "- Training data is for building the model;\n",
    "- Validation data is for *tweaking* the model;\n",
    "- Testing data is for evaluating the model on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Think of **training** data as what you study for a test\n",
    "- Think of **validation** data is using a practice test (note sometimes called **dev**)\n",
    "- Think of **testing** data as what you use to judge the model\n",
    "    - A **holdout** set is when your test dataset is never used for training (unlike in cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](https://scikit-learn.org/stable/_images/grid_search_workflow.png)\n",
    "> Image from Scikit-Learn https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Split data into training data and a holdout test\n",
    "2. Design a model\n",
    "3. Evaluate how well it generalizes with **cross-validation** (only training data)\n",
    "4. Determine if we should adjust model, use cross-validation to evaluate, and repeat\n",
    "5. After iteratively adjusting your model, do a _final_ evaluation with the holdout test set\n",
    "6. DON'T TOUCH THE MODEL!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### The Power of the Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This \"tweaking\" includes most of all the fine-tuning of model parameters (see below). Think of what this three-way distinction allows us to do:\n",
    "\n",
    "I can build a model on some data. Then, **before** I introduce the model to the testing data, I can introduce it to a different batch of data (the validation set). With respect to the validation data I can do things like measure error and tweak model parameters to minimize that error. Of course, I also don't want to lose sight of the error on the training data. If the model error has been minimized on the training error, then of course any changes I make to the model parameters will take me away from that minimum. But still the new information I've gained by looking at the model's performance on the validation data is valuable. I might for example go with a kind of compromising model whose parameters produce an error that's not too big on the training data and not too big on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question**: What's different about this procedure from what we've described before? Aren't I just calling the test data \"validation data\" now? Is there any substantive difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### From Validation to Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since my model will \"see\" the validation data in any case, I might as well use *all* of my training data to validate my model! How do I do this?\n",
    "\n",
    "Cross-validation works like this: First I'll partition my training data into $k$-many *folds*. Then I'll train a model on $k-1$ of those folds and \"test\" it on the remaining fold. I'll do this for all possible divisions of my $k$ folds into $k-1$ training folds and a single \"testing\" fold. Since there are $k\\choose 1$$=k$-many ways of doing this, I'll be building $k$-many models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Python Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.2</td>\n",
       "      <td>15.8</td>\n",
       "      <td>215.0</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>216.0</td>\n",
       "      <td>5550.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>35.3</td>\n",
       "      <td>18.9</td>\n",
       "      <td>187.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>43.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>4575.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Dream</td>\n",
       "      <td>38.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3950.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "269  Gentoo  Biscoe            45.2           15.8              215.0   \n",
       "231  Gentoo  Biscoe            49.0           16.1              216.0   \n",
       "25   Adelie  Biscoe            35.3           18.9              187.0   \n",
       "328  Gentoo  Biscoe            43.3           14.0              208.0   \n",
       "36   Adelie   Dream            38.8           20.0              190.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "269       5300.0    Male  \n",
       "231       5550.0    Male  \n",
       "25        3800.0  Female  \n",
       "328       4575.0  Female  \n",
       "36        3950.0    Male  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds = sns.load_dataset('penguins')\n",
    "birds.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "birds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For simplicity's sake we'll limit our analysis to the numeric columns.\n",
    "# Newer versions of seaborn have \"bill\" instead of \"culmen\".\n",
    "\n",
    "numeric = birds[['bill_length_mm', 'bill_depth_mm',\n",
    "                 'flipper_length_mm', 'body_mass_g']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We'll drop the rows with null values\n",
    "\n",
    "numeric = numeric.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Suppose I want to model `body_mass_g` as a function of the other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = numeric.drop('body_mass_g', axis=1)\n",
    "y = numeric['body_mass_g']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll make ten models and record our evaluations of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# instantiate algorithm\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# instantiate cross val\n",
    "cv_results = cross_validate(\n",
    "X=X,\n",
    "y=y,\n",
    "estimator=lr,\n",
    "cv=10,\n",
    "scoring=('r2', 'neg_root_mean_squared_error'),\n",
    "return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_time', 'score_time', 'test_r2', 'train_r2', 'test_neg_root_mean_squared_error', 'train_neg_root_mean_squared_error'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results\n",
    "cv_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7655940618556454"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.get('train_r2').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.178797944028394"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.get('test_r2').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385.6013433700433 6.022188349610129\n"
     ]
    }
   ],
   "source": [
    "# Compare the results\n",
    "print(-1*cv_results.get('train_neg_root_mean_squared_error').mean(),\n",
    "      cv_results.get('train_neg_root_mean_squared_error').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410.30011303353433 66.77778278814547\n"
     ]
    }
   ],
   "source": [
    "print(-1*cv_results.get('test_neg_root_mean_squared_error').mean(),\n",
    "      cv_results.get('test_neg_root_mean_squared_error').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cv_results_df(cv_model):\n",
    "    '''\n",
    "    Return a Dataframe with the cross validation results\n",
    "    '''\n",
    "    cv_df = pd.DataFrame(cv_model)\n",
    "    cv_df['test_rmse'] = (np.sqrt(-cv_df['test_neg_root_mean_squared_error']))\n",
    "    cv_df['train_rmse'] = (np.sqrt(-cv_df['train_neg_root_mean_squared_error']))\n",
    "    cv_df['r2_diff'] = cv_df.train_r2 - cv_df.test_r2\n",
    "    \n",
    "    return cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_peek(model,X,y):\n",
    "    '''\n",
    "    Print R^2 and RMSE for a given model and data\n",
    "    '''\n",
    "    r2 = model.score(X,y)\n",
    "    rmse = mean_squared_error(model.predict(X), y, squared=False)\n",
    "    \n",
    "    print(f'{model} has the following scores:\\n'\n",
    "          f'    R^2 of {r2}\\n'\n",
    "          f'    RMSE of {rmse}')\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# All results in a dataframe\n",
    "lrl_df = cv_results_df(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>r2_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>-0.427257</td>\n",
       "      <td>0.782737</td>\n",
       "      <td>-460.847264</td>\n",
       "      <td>-380.250340</td>\n",
       "      <td>21.467353</td>\n",
       "      <td>19.500009</td>\n",
       "      <td>1.209994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005999</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.347599</td>\n",
       "      <td>0.771805</td>\n",
       "      <td>-418.854757</td>\n",
       "      <td>-383.954322</td>\n",
       "      <td>20.465941</td>\n",
       "      <td>19.594752</td>\n",
       "      <td>0.424206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.264570</td>\n",
       "      <td>0.777014</td>\n",
       "      <td>-395.699147</td>\n",
       "      <td>-386.329019</td>\n",
       "      <td>19.892188</td>\n",
       "      <td>19.655254</td>\n",
       "      <td>0.512444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.189408</td>\n",
       "      <td>0.774085</td>\n",
       "      <td>-418.197494</td>\n",
       "      <td>-384.161537</td>\n",
       "      <td>20.449878</td>\n",
       "      <td>19.600039</td>\n",
       "      <td>0.584677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>-0.236440</td>\n",
       "      <td>0.771799</td>\n",
       "      <td>-354.150941</td>\n",
       "      <td>-390.879550</td>\n",
       "      <td>18.818898</td>\n",
       "      <td>19.770674</td>\n",
       "      <td>1.008239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>-0.111243</td>\n",
       "      <td>0.780943</td>\n",
       "      <td>-495.145082</td>\n",
       "      <td>-380.501338</td>\n",
       "      <td>22.251856</td>\n",
       "      <td>19.506443</td>\n",
       "      <td>0.892186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010995</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.644393</td>\n",
       "      <td>0.771697</td>\n",
       "      <td>-498.710602</td>\n",
       "      <td>-375.768902</td>\n",
       "      <td>22.331829</td>\n",
       "      <td>19.384760</td>\n",
       "      <td>0.127305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.466686</td>\n",
       "      <td>0.750022</td>\n",
       "      <td>-353.165171</td>\n",
       "      <td>-390.714370</td>\n",
       "      <td>18.792689</td>\n",
       "      <td>19.766496</td>\n",
       "      <td>0.283336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.703894</td>\n",
       "      <td>0.733384</td>\n",
       "      <td>-270.618939</td>\n",
       "      <td>-397.931122</td>\n",
       "      <td>16.450500</td>\n",
       "      <td>19.948211</td>\n",
       "      <td>0.029490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>-0.053629</td>\n",
       "      <td>0.742455</td>\n",
       "      <td>-437.611735</td>\n",
       "      <td>-385.522934</td>\n",
       "      <td>20.919171</td>\n",
       "      <td>19.634738</td>\n",
       "      <td>0.796084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_r2  train_r2  test_neg_root_mean_squared_error  \\\n",
       "0  0.002998    0.002998 -0.427257  0.782737                       -460.847264   \n",
       "1  0.005999    0.003995  0.347599  0.771805                       -418.854757   \n",
       "2  0.002997    0.002999  0.264570  0.777014                       -395.699147   \n",
       "3  0.002999    0.007000  0.189408  0.774085                       -418.197494   \n",
       "4  0.003999    0.001998 -0.236440  0.771799                       -354.150941   \n",
       "5  0.003000    0.002999 -0.111243  0.780943                       -495.145082   \n",
       "6  0.010995    0.002994  0.644393  0.771697                       -498.710602   \n",
       "7  0.002998    0.002997  0.466686  0.750022                       -353.165171   \n",
       "8  0.001998    0.002997  0.703894  0.733384                       -270.618939   \n",
       "9  0.007007    0.004986 -0.053629  0.742455                       -437.611735   \n",
       "\n",
       "   train_neg_root_mean_squared_error  test_rmse  train_rmse   r2_diff  \n",
       "0                        -380.250340  21.467353   19.500009  1.209994  \n",
       "1                        -383.954322  20.465941   19.594752  0.424206  \n",
       "2                        -386.329019  19.892188   19.655254  0.512444  \n",
       "3                        -384.161537  20.449878   19.600039  0.584677  \n",
       "4                        -390.879550  18.818898   19.770674  1.008239  \n",
       "5                        -380.501338  22.251856   19.506443  0.892186  \n",
       "6                        -375.768902  22.331829   19.384760  0.127305  \n",
       "7                        -390.714370  18.792689   19.766496  0.283336  \n",
       "8                        -397.931122  16.450500   19.948211  0.029490  \n",
       "9                        -385.522934  20.919171   19.634738  0.796084  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>0.178798</td>\n",
       "      <td>0.378479</td>\n",
       "      <td>0.143246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>0.765594</td>\n",
       "      <td>0.017197</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_rmse</th>\n",
       "      <td>20.184030</td>\n",
       "      <td>1.796610</td>\n",
       "      <td>3.227809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_rmse</th>\n",
       "      <td>19.636138</td>\n",
       "      <td>0.161386</td>\n",
       "      <td>0.026045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean       std       var\n",
       "test_r2      0.178798  0.378479  0.143246\n",
       "train_r2     0.765594  0.017197  0.000296\n",
       "test_rmse   20.184030  1.796610  3.227809\n",
       "train_rmse  19.636138  0.161386  0.026045"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate and reduce\n",
    "lrl_df[['test_r2', 'train_r2', 'test_rmse', 'train_rmse']].agg(['mean', 'std', 'var']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preventing Overfitting - Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Again, complex models are very flexible in the patterns that they can model but this also means that they can easily find patterns that are simply statistical flukes of one particular dataset rather than patterns reflective of the underlying data-generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When a model has large weights, the model is \"too confident\". This translates to a model with high variance which puts it in danger of overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/punishing_model_metaphor.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need to punish large (confident) weights by contributing them to the error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Some Types of Regularization:**\n",
    "\n",
    "1. Reducing the number of features\n",
    "2. Increasing the amount of data\n",
    "3. Popular techniques: Ridge, Lasso, Elastic Net\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Strategy Behind Ridge / Lasso / Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Overfit models overestimate the relevance that predictors have for a target. Thus overfit models tend to have **overly large coefficients**. \n",
    "\n",
    "Generally, overfitting models come from a result of high model variance. High model variance can be caused by:\n",
    "\n",
    "- having irrelevant or too many predictors\n",
    "- multicollinearity\n",
    "- large coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The evaluation of many models, linear regression included, proceeds by measuring its **error**, some quantifiable expression of the discrepancy between its predictions and the ground truth. The best-fit line of LR, for example, minimizes the sum of squared residuals.\n",
    "\n",
    "Our new idea, then, will be ***to add a term representing the size of our coefficients to our loss function***. This will be our **cost function** $J$.\n",
    "\n",
    "The goal will still be to minimize this new function, but we can make progress toward this minimum *either* by reducing the size of our residuals *or* by reducing the size of our coefficients.\n",
    "\n",
    "Since coefficients can be either negative or positive, we have the familiar difficulty that we can't simply add them up to get a sense of how large they are in general. Once again there are two natural choices: We could focus either on the squares or the absolute values of the coefficients. The former strategy is the basis for **Ridge** (also called Tikhonov) regularization; the latter strategy results in **Lasso** (Least Absolute Shrinkage and Selection Operator) regularization.\n",
    "\n",
    "These tools, as we shall see, are easily implemented with `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Regularization is about introducing a factor into our model designed to enforce the stricture that the coefficients stay small, by _penalizing_ the ones that get too large.\n",
    "\n",
    "That is, we'll alter our loss function so that the goal now is not merely to minimize the difference between actual values and our model's predicted values. Rather, we'll add in a term to our loss function that represents the sizes of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Ridge and Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first problem is about picking up on noise rather than signal.\n",
    "The second problem is about having a least-squares estimate that is highly sensitive to random error.\n",
    "The third is about having highly sensitive predictors.\n",
    "\n",
    "Regularization is about introducing a factor into our model designed to enforce the stricture that the coefficients stay small, by penalizing the ones that get too large.\n",
    "\n",
    "That is, we'll alter our loss function so that the goal now is not merely to minimize the difference between actual values and our model's predicted values. Rather, we'll add in a term to our loss function that represents the sizes of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Lasso: L1 Regularization - Absolute Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Tend to get sparse vectors (small weights go to 0)\n",
    "- Reduce number of weights\n",
    "- Good feature selection to pick out importance\n",
    "\n",
    "$$ J(W,b) = -\\dfrac{1}{m} \\sum^m_{i=1}\\big[\\mathcal{L}(\\hat y_i, y_i)+ \\lambda|w_i| \\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Ridge: L2 Regularization - Squared Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Not sparse vectors (weights homogeneous & small)\n",
    "- Tends to give better results for training\n",
    "\n",
    "    \n",
    "$$ J(W,b) = -\\dfrac{1}{m} \\sum^m_{i=1}\\big[\\mathcal{L}(\\hat y_i, y_i)+ \\lambda w_i^2 \\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ü§î Which Do I Use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Typically you'll want to use L2 regularization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- For a given value of $\\lambda$, the ridge makes for a gentler reining in of runaway coefficients. When in doubt, try ridge first.\n",
    "- The lasso will more quickly reduce the contribution of individual predictors down to insignificance. It is therefore most useful for trimming through the fat of datasets with many predictors or if a model with very few predictors is especially desirable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Aside: Comparing L1 & L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is a bit subtle: \n",
    "- Consider vectors: [1,0] & [0.5, 0.5] \n",
    "- Recall we want smallest value for our value\n",
    "- L2 prefers [0.5,0.5] over [1,0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For a nice discussion of these methods in Python, see [this post](https://towardsdatascience.com/ridge-and-lasso-regression-a-complete-guide-with-python-scikit-learn-e20e34bcbf0b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### The Best of Both Worlds: Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is a combination of L1 and L2 regularization called the Elastic Net that can also be used. The idea is to use a scaled linear combination of the lasso and the ridge, where the weights add up to 100%. We might want 50% of each, but we also might want, say, 10% Lasso and 90% Ridge.\n",
    "\n",
    "The loss function for an Elastic Net Regression looks like this:\n",
    "\n",
    "Elastic Net:\n",
    "\n",
    "$\\rho\\Sigma^{n_{obs.}}_{i=1}[(y_i - \\Sigma^{n_{feat.}}_{j=0}\\beta_j\\times x_{ij})^2 + \\lambda\\Sigma^{n_{feat.}}_{j=0}|\\beta_j|] + (1 - \\rho)\\Sigma^{n_{obs.}}_{i=1}[(y_i - \\Sigma^{n_{feat.}}_{j=0}\\beta_j\\times x_{ij})^2 + \\lambda\\Sigma^{n_{feat.}}_{j=0}\\beta^2_j]$\n",
    "\n",
    "Sometimes you will see this loss function represented with different scaling terms, but the basic idea is to have a combination of L1 and L2 regularization terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Code it Out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Producing an Overfit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can often produce an overfit model by including **interaction terms**. We'll start over with the penguins dataset. This time we'll include the categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "birds = sns.load_dataset('penguins')\n",
    "birds = birds.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "4       3450.0  Female  \n",
       "5       3650.0    Male  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        birds.drop('body_mass_g', axis=1),\n",
    "                                        birds['body_mass_g'],\n",
    "                                        random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>x0_Chinstrap</th>\n",
       "      <th>x0_Gentoo</th>\n",
       "      <th>x1_Dream</th>\n",
       "      <th>x1_Torgersen</th>\n",
       "      <th>x2_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>55.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>43.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>47.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>53.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bill_length_mm  bill_depth_mm  flipper_length_mm  x0_Chinstrap  \\\n",
       "321            55.9           17.0              228.0           0.0   \n",
       "265            43.6           13.9              217.0           0.0   \n",
       "36             38.8           20.0              190.0           0.0   \n",
       "308            47.5           14.0              212.0           0.0   \n",
       "191            53.5           19.9              205.0           1.0   \n",
       "\n",
       "     x0_Gentoo  x1_Dream  x1_Torgersen  x2_Male  \n",
       "321        1.0       0.0           0.0      1.0  \n",
       "265        1.0       0.0           0.0      0.0  \n",
       "36         0.0       1.0           0.0      1.0  \n",
       "308        1.0       0.0           0.0      0.0  \n",
       "191        0.0       1.0           0.0      1.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking in other features (category)\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "dummies = ohe.fit_transform(X_train[['species', 'island', 'sex']])\n",
    "\n",
    "# Getting a DF\n",
    "dummies_df = pd.DataFrame(dummies.todense(), columns=ohe.get_feature_names(),\n",
    "                         index=X_train.index)\n",
    "\n",
    "# What we'll feed int our model\n",
    "X_train_df = pd.concat([X_train[['bill_length_mm', 'bill_depth_mm',\n",
    "                                'flipper_length_mm']], dummies_df], axis=1)\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note the same transformation (not FIT) to match structure\n",
    "test_dummies = ohe.transform(X_test[['species', 'island', 'sex']])\n",
    "test_df = pd.DataFrame(test_dummies.todense(), columns=ohe.get_feature_names(),\n",
    "                       index=X_test.index)\n",
    "X_test_df = pd.concat([X_test[['bill_length_mm', 'bill_depth_mm',\n",
    "                              'flipper_length_mm']], test_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Dummy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Instantiate and Fit\n",
    "dum = DummyRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyRegressor()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum.fit(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Val!\n",
    "dum.score(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Val!\n",
    "cv_results = cross_validate(\n",
    "X=X,\n",
    "y=y,\n",
    "estimator=dum,\n",
    "cv=10,\n",
    "scoring=('r2','neg_root_mean_squared_error'),\n",
    "return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create results df\n",
    "dum_df = cv_results_df(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>-2.386016</td>\n",
       "      <td>1.782914</td>\n",
       "      <td>3.178782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_rmse</th>\n",
       "      <td>28.773577</td>\n",
       "      <td>3.218245</td>\n",
       "      <td>10.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_rmse</th>\n",
       "      <td>28.238390</td>\n",
       "      <td>0.380108</td>\n",
       "      <td>0.144482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean       std        var\n",
       "test_r2     -2.386016  1.782914   3.178782\n",
       "train_r2     0.000000  0.000000   0.000000\n",
       "test_rmse   28.773577  3.218245  10.357100\n",
       "train_rmse  28.238390  0.380108   0.144482"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate for clarity\n",
    "dum_df[['test_r2', 'train_r2', 'test_rmse', 'train_rmse']].agg(['mean', 'std', 'var']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Peeking at the end (test data)üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test_peek\n",
    "pens_preds = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### First simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's do some cross-validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr1 = LinearRegression()\n",
    "lr1.fit(X_train_df, y_train)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "                X=X_train_df, \n",
    "                y=y_train,\n",
    "                estimator=lr1, \n",
    "                cv=10,\n",
    "                scoring=('r2', 'neg_root_mean_squared_error'),\n",
    "                return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>r2_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.860923</td>\n",
       "      <td>0.868049</td>\n",
       "      <td>-297.908931</td>\n",
       "      <td>-294.399029</td>\n",
       "      <td>17.260039</td>\n",
       "      <td>17.158060</td>\n",
       "      <td>0.007126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.688458</td>\n",
       "      <td>0.871848</td>\n",
       "      <td>-291.599923</td>\n",
       "      <td>-295.547950</td>\n",
       "      <td>17.076297</td>\n",
       "      <td>17.191508</td>\n",
       "      <td>0.183390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.887306</td>\n",
       "      <td>0.866394</td>\n",
       "      <td>-281.783253</td>\n",
       "      <td>-295.832052</td>\n",
       "      <td>16.786401</td>\n",
       "      <td>17.199769</td>\n",
       "      <td>-0.020911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.853155</td>\n",
       "      <td>0.869021</td>\n",
       "      <td>-358.307739</td>\n",
       "      <td>-287.462703</td>\n",
       "      <td>18.929018</td>\n",
       "      <td>16.954725</td>\n",
       "      <td>0.015866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.855551</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>-260.323672</td>\n",
       "      <td>-298.159999</td>\n",
       "      <td>16.134549</td>\n",
       "      <td>17.267310</td>\n",
       "      <td>0.013647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.887796</td>\n",
       "      <td>0.866257</td>\n",
       "      <td>-281.502670</td>\n",
       "      <td>-295.749181</td>\n",
       "      <td>16.778041</td>\n",
       "      <td>17.197360</td>\n",
       "      <td>-0.021538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.877968</td>\n",
       "      <td>0.866807</td>\n",
       "      <td>-309.167567</td>\n",
       "      <td>-293.404763</td>\n",
       "      <td>17.583161</td>\n",
       "      <td>17.129062</td>\n",
       "      <td>-0.011161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.718392</td>\n",
       "      <td>0.876828</td>\n",
       "      <td>-319.735036</td>\n",
       "      <td>-291.727523</td>\n",
       "      <td>17.881136</td>\n",
       "      <td>17.080033</td>\n",
       "      <td>0.158436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.850803</td>\n",
       "      <td>0.869645</td>\n",
       "      <td>-331.386498</td>\n",
       "      <td>-290.821390</td>\n",
       "      <td>18.204024</td>\n",
       "      <td>17.053486</td>\n",
       "      <td>0.018842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.862633</td>\n",
       "      <td>0.869061</td>\n",
       "      <td>-316.033660</td>\n",
       "      <td>-292.375231</td>\n",
       "      <td>17.777336</td>\n",
       "      <td>17.098983</td>\n",
       "      <td>0.006428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_r2  train_r2  test_neg_root_mean_squared_error  \\\n",
       "0  0.004997    0.002998  0.860923  0.868049                       -297.908931   \n",
       "1  0.003997    0.003000  0.688458  0.871848                       -291.599923   \n",
       "2  0.001999    0.004001  0.887306  0.866394                       -281.783253   \n",
       "3  0.006993    0.002996  0.853155  0.869021                       -358.307739   \n",
       "4  0.001998    0.002998  0.855551  0.869198                       -260.323672   \n",
       "5  0.003998    0.002998  0.887796  0.866257                       -281.502670   \n",
       "6  0.002998    0.002999  0.877968  0.866807                       -309.167567   \n",
       "7  0.001998    0.001999  0.718392  0.876828                       -319.735036   \n",
       "8  0.002995    0.002997  0.850803  0.869645                       -331.386498   \n",
       "9  0.002998    0.001999  0.862633  0.869061                       -316.033660   \n",
       "\n",
       "   train_neg_root_mean_squared_error  test_rmse  train_rmse   r2_diff  \n",
       "0                        -294.399029  17.260039   17.158060  0.007126  \n",
       "1                        -295.547950  17.076297   17.191508  0.183390  \n",
       "2                        -295.832052  16.786401   17.199769 -0.020911  \n",
       "3                        -287.462703  18.929018   16.954725  0.015866  \n",
       "4                        -298.159999  16.134549   17.267310  0.013647  \n",
       "5                        -295.749181  16.778041   17.197360 -0.021538  \n",
       "6                        -293.404763  17.583161   17.129062 -0.011161  \n",
       "7                        -291.727523  17.881136   17.080033  0.158436  \n",
       "8                        -290.821390  18.204024   17.053486  0.018842  \n",
       "9                        -292.375231  17.777336   17.098983  0.006428  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1_df = cv_results_df(cv_results)\n",
    "lr1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr1_df[['test_r2','train_r2','test_rmse','train_rmse']].agg(['mean','std']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Peeking at the end (test data) üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression() has the following scores:\n",
      "    R^2 of 0.8934228693424331\n",
      "    RMSE of 253.98121177477861\n"
     ]
    }
   ],
   "source": [
    "test_peek(lr1, X_test_df, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Add Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "\n",
    "X_poly_train = pf.fit_transform(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'x0',\n",
       " 'x1',\n",
       " 'x2',\n",
       " 'x3',\n",
       " 'x4',\n",
       " 'x5',\n",
       " 'x6',\n",
       " 'x7',\n",
       " 'x0^2',\n",
       " 'x0 x1',\n",
       " 'x0 x2',\n",
       " 'x0 x3',\n",
       " 'x0 x4',\n",
       " 'x0 x5',\n",
       " 'x0 x6',\n",
       " 'x0 x7',\n",
       " 'x1^2',\n",
       " 'x1 x2',\n",
       " 'x1 x3',\n",
       " 'x1 x4',\n",
       " 'x1 x5',\n",
       " 'x1 x6',\n",
       " 'x1 x7',\n",
       " 'x2^2',\n",
       " 'x2 x3',\n",
       " 'x2 x4',\n",
       " 'x2 x5',\n",
       " 'x2 x6',\n",
       " 'x2 x7',\n",
       " 'x3^2',\n",
       " 'x3 x4',\n",
       " 'x3 x5',\n",
       " 'x3 x6',\n",
       " 'x3 x7',\n",
       " 'x4^2',\n",
       " 'x4 x5',\n",
       " 'x4 x6',\n",
       " 'x4 x7',\n",
       " 'x5^2',\n",
       " 'x5 x6',\n",
       " 'x5 x7',\n",
       " 'x6^2',\n",
       " 'x6 x7',\n",
       " 'x7^2',\n",
       " 'x0^3',\n",
       " 'x0^2 x1',\n",
       " 'x0^2 x2',\n",
       " 'x0^2 x3',\n",
       " 'x0^2 x4',\n",
       " 'x0^2 x5',\n",
       " 'x0^2 x6',\n",
       " 'x0^2 x7',\n",
       " 'x0 x1^2',\n",
       " 'x0 x1 x2',\n",
       " 'x0 x1 x3',\n",
       " 'x0 x1 x4',\n",
       " 'x0 x1 x5',\n",
       " 'x0 x1 x6',\n",
       " 'x0 x1 x7',\n",
       " 'x0 x2^2',\n",
       " 'x0 x2 x3',\n",
       " 'x0 x2 x4',\n",
       " 'x0 x2 x5',\n",
       " 'x0 x2 x6',\n",
       " 'x0 x2 x7',\n",
       " 'x0 x3^2',\n",
       " 'x0 x3 x4',\n",
       " 'x0 x3 x5',\n",
       " 'x0 x3 x6',\n",
       " 'x0 x3 x7',\n",
       " 'x0 x4^2',\n",
       " 'x0 x4 x5',\n",
       " 'x0 x4 x6',\n",
       " 'x0 x4 x7',\n",
       " 'x0 x5^2',\n",
       " 'x0 x5 x6',\n",
       " 'x0 x5 x7',\n",
       " 'x0 x6^2',\n",
       " 'x0 x6 x7',\n",
       " 'x0 x7^2',\n",
       " 'x1^3',\n",
       " 'x1^2 x2',\n",
       " 'x1^2 x3',\n",
       " 'x1^2 x4',\n",
       " 'x1^2 x5',\n",
       " 'x1^2 x6',\n",
       " 'x1^2 x7',\n",
       " 'x1 x2^2',\n",
       " 'x1 x2 x3',\n",
       " 'x1 x2 x4',\n",
       " 'x1 x2 x5',\n",
       " 'x1 x2 x6',\n",
       " 'x1 x2 x7',\n",
       " 'x1 x3^2',\n",
       " 'x1 x3 x4',\n",
       " 'x1 x3 x5',\n",
       " 'x1 x3 x6',\n",
       " 'x1 x3 x7',\n",
       " 'x1 x4^2',\n",
       " 'x1 x4 x5',\n",
       " 'x1 x4 x6',\n",
       " 'x1 x4 x7',\n",
       " 'x1 x5^2',\n",
       " 'x1 x5 x6',\n",
       " 'x1 x5 x7',\n",
       " 'x1 x6^2',\n",
       " 'x1 x6 x7',\n",
       " 'x1 x7^2',\n",
       " 'x2^3',\n",
       " 'x2^2 x3',\n",
       " 'x2^2 x4',\n",
       " 'x2^2 x5',\n",
       " 'x2^2 x6',\n",
       " 'x2^2 x7',\n",
       " 'x2 x3^2',\n",
       " 'x2 x3 x4',\n",
       " 'x2 x3 x5',\n",
       " 'x2 x3 x6',\n",
       " 'x2 x3 x7',\n",
       " 'x2 x4^2',\n",
       " 'x2 x4 x5',\n",
       " 'x2 x4 x6',\n",
       " 'x2 x4 x7',\n",
       " 'x2 x5^2',\n",
       " 'x2 x5 x6',\n",
       " 'x2 x5 x7',\n",
       " 'x2 x6^2',\n",
       " 'x2 x6 x7',\n",
       " 'x2 x7^2',\n",
       " 'x3^3',\n",
       " 'x3^2 x4',\n",
       " 'x3^2 x5',\n",
       " 'x3^2 x6',\n",
       " 'x3^2 x7',\n",
       " 'x3 x4^2',\n",
       " 'x3 x4 x5',\n",
       " 'x3 x4 x6',\n",
       " 'x3 x4 x7',\n",
       " 'x3 x5^2',\n",
       " 'x3 x5 x6',\n",
       " 'x3 x5 x7',\n",
       " 'x3 x6^2',\n",
       " 'x3 x6 x7',\n",
       " 'x3 x7^2',\n",
       " 'x4^3',\n",
       " 'x4^2 x5',\n",
       " 'x4^2 x6',\n",
       " 'x4^2 x7',\n",
       " 'x4 x5^2',\n",
       " 'x4 x5 x6',\n",
       " 'x4 x5 x7',\n",
       " 'x4 x6^2',\n",
       " 'x4 x6 x7',\n",
       " 'x4 x7^2',\n",
       " 'x5^3',\n",
       " 'x5^2 x6',\n",
       " 'x5^2 x7',\n",
       " 'x5 x6^2',\n",
       " 'x5 x6 x7',\n",
       " 'x5 x7^2',\n",
       " 'x6^3',\n",
       " 'x6^2 x7',\n",
       " 'x6 x7^2',\n",
       " 'x7^3']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at feature names\n",
    "pf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Don't forget test!\n",
    "X_poly_test = pf.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Train the model and evaluate (with cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "poly_lr = LinearRegression()\n",
    "poly_lr.fit(X_poly_train, y_train)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "                X=X_poly_train, \n",
    "                y=y_train,\n",
    "                estimator=poly_lr, \n",
    "                cv=10,\n",
    "                scoring=('r2', 'neg_root_mean_squared_error'),\n",
    "                return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>r2_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.584159</td>\n",
       "      <td>0.812745</td>\n",
       "      <td>-515.133357</td>\n",
       "      <td>-350.708379</td>\n",
       "      <td>22.696549</td>\n",
       "      <td>18.727210</td>\n",
       "      <td>0.228586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>-0.981820</td>\n",
       "      <td>0.905867</td>\n",
       "      <td>-735.463183</td>\n",
       "      <td>-253.300255</td>\n",
       "      <td>27.119424</td>\n",
       "      <td>15.915409</td>\n",
       "      <td>1.887687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.578837</td>\n",
       "      <td>0.871218</td>\n",
       "      <td>-544.739633</td>\n",
       "      <td>-290.442263</td>\n",
       "      <td>23.339658</td>\n",
       "      <td>17.042367</td>\n",
       "      <td>0.292381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.672008</td>\n",
       "      <td>0.867914</td>\n",
       "      <td>-535.498073</td>\n",
       "      <td>-288.675057</td>\n",
       "      <td>23.140831</td>\n",
       "      <td>16.990440</td>\n",
       "      <td>0.195906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0.136035</td>\n",
       "      <td>0.876303</td>\n",
       "      <td>-636.654813</td>\n",
       "      <td>-289.948305</td>\n",
       "      <td>25.232020</td>\n",
       "      <td>17.027868</td>\n",
       "      <td>0.740269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.513485</td>\n",
       "      <td>0.892494</td>\n",
       "      <td>-586.173244</td>\n",
       "      <td>-265.157813</td>\n",
       "      <td>24.211015</td>\n",
       "      <td>16.283667</td>\n",
       "      <td>0.379009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.110733</td>\n",
       "      <td>0.877728</td>\n",
       "      <td>-834.589338</td>\n",
       "      <td>-281.118169</td>\n",
       "      <td>28.889260</td>\n",
       "      <td>16.766579</td>\n",
       "      <td>0.766995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.174701</td>\n",
       "      <td>0.895326</td>\n",
       "      <td>-547.360242</td>\n",
       "      <td>-268.930720</td>\n",
       "      <td>23.395731</td>\n",
       "      <td>16.399107</td>\n",
       "      <td>0.720625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.914147</td>\n",
       "      <td>-364.952213</td>\n",
       "      <td>-236.015461</td>\n",
       "      <td>19.103722</td>\n",
       "      <td>15.362795</td>\n",
       "      <td>0.095098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.566115</td>\n",
       "      <td>0.805331</td>\n",
       "      <td>-561.667358</td>\n",
       "      <td>-356.496396</td>\n",
       "      <td>23.699522</td>\n",
       "      <td>18.881112</td>\n",
       "      <td>0.239216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_r2  train_r2  test_neg_root_mean_squared_error  \\\n",
       "0  0.005996    0.000999  0.584159  0.812745                       -515.133357   \n",
       "1  0.003997    0.000998 -0.981820  0.905867                       -735.463183   \n",
       "2  0.005996    0.000999  0.578837  0.871218                       -544.739633   \n",
       "3  0.004997    0.001000  0.672008  0.867914                       -535.498073   \n",
       "4  0.003997    0.006006  0.136035  0.876303                       -636.654813   \n",
       "5  0.007990    0.002000  0.513485  0.892494                       -586.173244   \n",
       "6  0.003996    0.001000  0.110733  0.877728                       -834.589338   \n",
       "7  0.003998    0.000999  0.174701  0.895326                       -547.360242   \n",
       "8  0.003998    0.000999  0.819048  0.914147                       -364.952213   \n",
       "9  0.003998    0.000999  0.566115  0.805331                       -561.667358   \n",
       "\n",
       "   train_neg_root_mean_squared_error  test_rmse  train_rmse   r2_diff  \n",
       "0                        -350.708379  22.696549   18.727210  0.228586  \n",
       "1                        -253.300255  27.119424   15.915409  1.887687  \n",
       "2                        -290.442263  23.339658   17.042367  0.292381  \n",
       "3                        -288.675057  23.140831   16.990440  0.195906  \n",
       "4                        -289.948305  25.232020   17.027868  0.740269  \n",
       "5                        -265.157813  24.211015   16.283667  0.379009  \n",
       "6                        -281.118169  28.889260   16.766579  0.766995  \n",
       "7                        -268.930720  23.395731   16.399107  0.720625  \n",
       "8                        -236.015461  19.103722   15.362795  0.095098  \n",
       "9                        -356.496396  23.699522   18.881112  0.239216  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_lr_df = cv_results_df(cv_results)\n",
    "poly_lr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>0.317330</td>\n",
       "      <td>0.516522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>0.871907</td>\n",
       "      <td>0.036381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_rmse</th>\n",
       "      <td>24.082773</td>\n",
       "      <td>2.633792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_rmse</th>\n",
       "      <td>16.939655</td>\n",
       "      <td>1.119204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean       std\n",
       "test_r2      0.317330  0.516522\n",
       "train_r2     0.871907  0.036381\n",
       "test_rmse   24.082773  2.633792\n",
       "train_rmse  16.939655  1.119204"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_lr_df[['test_r2','train_r2','test_rmse','train_rmse']].agg(['mean','std']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 165)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Peeking at the end (test data) üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression() has the following scores:\n",
      "    R^2 of -1.0339211512554716\n",
      "    RMSE of 1109.5238328640169\n"
     ]
    }
   ],
   "source": [
    "test_peek(poly_lr, X_poly_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Ridge (L2) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "\n",
    "# You should always be sure to _standardize_ your data before\n",
    "# applying regularization!\n",
    "\n",
    "X_train_processed = pf.fit_transform(ss.fit_transform(X_train_df))\n",
    "X_test_processed = pf.transform(ss.transform(X_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100, random_state=42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Lambda' is the standard variable for the strength of the\n",
    "# regularization (as in the above formulas), but since lambda\n",
    "# is a key word in Python, these sklearn regularization tools\n",
    "# use 'alpha' instead.\n",
    "\n",
    "rr = Ridge(alpha=100, random_state=42)\n",
    "\n",
    "rr.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8858195769398121"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.score(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                X=X_train_processed, \n",
    "                y=y_train,\n",
    "                estimator=rr, \n",
    "                cv=10,\n",
    "                scoring=('r2', 'neg_root_mean_squared_error'),\n",
    "                return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>r2_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011997</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.833172</td>\n",
       "      <td>0.887689</td>\n",
       "      <td>-326.279557</td>\n",
       "      <td>-271.606183</td>\n",
       "      <td>18.063210</td>\n",
       "      <td>16.480479</td>\n",
       "      <td>0.054517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.752697</td>\n",
       "      <td>0.886945</td>\n",
       "      <td>-259.802668</td>\n",
       "      <td>-277.593632</td>\n",
       "      <td>16.118395</td>\n",
       "      <td>16.661141</td>\n",
       "      <td>0.134248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.867497</td>\n",
       "      <td>0.887010</td>\n",
       "      <td>-305.546388</td>\n",
       "      <td>-272.052584</td>\n",
       "      <td>17.479885</td>\n",
       "      <td>16.494017</td>\n",
       "      <td>0.019513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.868849</td>\n",
       "      <td>0.882072</td>\n",
       "      <td>-338.619009</td>\n",
       "      <td>-272.765027</td>\n",
       "      <td>18.401603</td>\n",
       "      <td>16.515600</td>\n",
       "      <td>0.013223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.888875</td>\n",
       "      <td>-294.355249</td>\n",
       "      <td>-274.819839</td>\n",
       "      <td>17.156784</td>\n",
       "      <td>16.577691</td>\n",
       "      <td>0.073560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.886860</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>-282.673728</td>\n",
       "      <td>-275.024370</td>\n",
       "      <td>16.812904</td>\n",
       "      <td>16.583859</td>\n",
       "      <td>-0.002515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.854184</td>\n",
       "      <td>0.886007</td>\n",
       "      <td>-337.955029</td>\n",
       "      <td>-271.434825</td>\n",
       "      <td>18.383553</td>\n",
       "      <td>16.475279</td>\n",
       "      <td>0.031822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.795933</td>\n",
       "      <td>0.888489</td>\n",
       "      <td>-272.178442</td>\n",
       "      <td>-277.574641</td>\n",
       "      <td>16.497831</td>\n",
       "      <td>16.660571</td>\n",
       "      <td>0.092556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.006998</td>\n",
       "      <td>0.861083</td>\n",
       "      <td>0.884216</td>\n",
       "      <td>-319.766588</td>\n",
       "      <td>-274.085644</td>\n",
       "      <td>17.882019</td>\n",
       "      <td>16.555532</td>\n",
       "      <td>0.023134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.863655</td>\n",
       "      <td>0.885394</td>\n",
       "      <td>-314.856103</td>\n",
       "      <td>-273.532975</td>\n",
       "      <td>17.744185</td>\n",
       "      <td>16.538832</td>\n",
       "      <td>0.021740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_r2  train_r2  test_neg_root_mean_squared_error  \\\n",
       "0  0.011997    0.000997  0.833172  0.887689                       -326.279557   \n",
       "1  0.002000    0.000999  0.752697  0.886945                       -259.802668   \n",
       "2  0.002000    0.000999  0.867497  0.887010                       -305.546388   \n",
       "3  0.001999    0.000998  0.868849  0.882072                       -338.619009   \n",
       "4  0.001999    0.000999  0.815315  0.888875                       -294.355249   \n",
       "5  0.001998    0.001000  0.886860  0.884345                       -282.673728   \n",
       "6  0.001999    0.001000  0.854184  0.886007                       -337.955029   \n",
       "7  0.002000    0.000998  0.795933  0.888489                       -272.178442   \n",
       "8  0.001000    0.006998  0.861083  0.884216                       -319.766588   \n",
       "9  0.002997    0.000998  0.863655  0.885394                       -314.856103   \n",
       "\n",
       "   train_neg_root_mean_squared_error  test_rmse  train_rmse   r2_diff  \n",
       "0                        -271.606183  18.063210   16.480479  0.054517  \n",
       "1                        -277.593632  16.118395   16.661141  0.134248  \n",
       "2                        -272.052584  17.479885   16.494017  0.019513  \n",
       "3                        -272.765027  18.401603   16.515600  0.013223  \n",
       "4                        -274.819839  17.156784   16.577691  0.073560  \n",
       "5                        -275.024370  16.812904   16.583859 -0.002515  \n",
       "6                        -271.434825  18.383553   16.475279  0.031822  \n",
       "7                        -277.574641  16.497831   16.660571  0.092556  \n",
       "8                        -274.085644  17.882019   16.555532  0.023134  \n",
       "9                        -273.532975  17.744185   16.538832  0.021740  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_df = cv_results_df(cv_results)\n",
    "rr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>0.839925</td>\n",
       "      <td>0.041108</td>\n",
       "      <td>0.001690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>0.886104</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_rmse</th>\n",
       "      <td>17.454037</td>\n",
       "      <td>0.788717</td>\n",
       "      <td>0.622075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_rmse</th>\n",
       "      <td>16.554300</td>\n",
       "      <td>0.067656</td>\n",
       "      <td>0.004577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean       std       var\n",
       "test_r2      0.839925  0.041108  0.001690\n",
       "train_r2     0.886104  0.002130  0.000005\n",
       "test_rmse   17.454037  0.788717  0.622075\n",
       "train_rmse  16.554300  0.067656  0.004577"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_df[['test_r2','train_r2','test_rmse','train_rmse']].agg(['mean','std', 'var']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Peeking at the end (test data) üëÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=100, random_state=42) has the following scores:\n",
      "    R^2 of 0.883587136658223\n",
      "    RMSE of 265.4422590836657\n"
     ]
    }
   ],
   "source": [
    "test_peek(rr, X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Much better! But how do we know which value of `alpha` to pick?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Optimizing the Regularization Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The regularization strength could sensibly be any nonnegative number, so there's no way to check \"all possible\" values. It's often useful to try several values that are different orders of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alphas = [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000, 10_000]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    rr = Ridge(alpha=alpha, random_state=42)\n",
    "    rr.fit(X_train_processed, y_train)\n",
    "    train_score = rr.score(X_train_processed, y_train)\n",
    "    test_score = rr.score(X_test_processed, y_test)\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots()\n",
    "plt.xscale('log')\n",
    "plt.title('Ridge $R^2$ as a function of regularization strength')\n",
    "ax.set_xlabel('Regularization strength $\\lambda$')\n",
    "ax.set_ylabel('$R^2$')\n",
    "ax.plot(alphas, train_scores, label='train')\n",
    "ax.plot(alphas, test_scores, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Notice how the values increase but then decrease? Regularization helps with overfitting, but if the strength of the regularization becomes too great, then large coefficients will be punished more than they really should. What happens then is that the original error between truth and model predictions becomes neglected as a quantity to be minimized, and the bias of the model begins to outweigh its variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It looks like the best value is somewhere around 100. If we wanted more precision, we could repeat the same sort of exercise with a set of alphas nearer to 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[92166.66673086278, 92162.4084074653, 92134.73845197324, 92677.06645627221]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [1e-3, 1e-2, 1e-1, 1]\n",
    "cv_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    rr = Ridge(alpha=alpha, random_state=42)\n",
    "    cv_results = cross_validate(\n",
    "                X=X_train_df, \n",
    "                y=y_train,\n",
    "                estimator=rr, \n",
    "                cv=10,\n",
    "                scoring=('neg_mean_squared_error'))\n",
    "    cv_scores.append(-np.median(cv_results['test_score']))\n",
    "\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.xscale('log')\n",
    "plt.title('Ridge MSE as a function of regularization strength')\n",
    "ax.set_xlabel('Regularization strength $\\lambda$')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.plot(alphas, cv_scores, label='cross-validated')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### LEVEL UP - Elastic Net!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Naturally, the Elastic Net has the same interface through sklearn as the other regularization tools! The only difference is that we now have to specify how much of each regularization term we want. The name of the parameter for this (represented by $\\rho$ above) in sklearn is `l1_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enet = ElasticNet(alpha=10, l1_ratio=0.1, random_state=42)\n",
    "\n",
    "enet.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enet.score(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enet.score(X_test_processed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Setting the `l1_ratio` to 1 is equivalent to the lasso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ratios = np.linspace(0.01, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for ratio in ratios:\n",
    "    enet = ElasticNet(alpha=100, l1_ratio=ratio, random_state=42)\n",
    "    enet.fit(X_train_processed, y_train)\n",
    "    preds.append(enet.predict(X_test_processed[0].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "lasso = Lasso(alpha=100, random_state=42)\n",
    "lasso.fit(X_train_processed, y_train)\n",
    "lasso_pred = lasso.predict(X_test_processed[0].reshape(1, -1))\n",
    "\n",
    "ax.plot(ratios, preds, label='elastic net')\n",
    "ax.scatter(1, lasso_pred, c='k', s=70, label='lasso')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Note on `ElasticNet()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Is an Elastic Net with `l1_ratio` set to 0 equivalent to the ridge? In theory yes. But in practice no. It looks like the `ElasticNet()` predictions on the first test data point as `l1_ratio` shrinks are tending toward some value around 3400. Let's check to see what prediction `Ridge()` gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=10, random_state=42)\n",
    "ridge.fit(X_train_processed, y_train)\n",
    "ridge.predict(X_test_processed[0].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you check the docstring for the `ElasticNet()` class you will see:\n",
    "- that the function being minimized is slightly different from what we saw above; and\n",
    "- that the results are unreliable when `l1_ratio` $\\leq 0.01$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Exercise**: Visualize the difference in this case between `ElasticNet(l1_ratio=0.01)` and `Ridge()` by making a scatterplot of each model's predicted values for the first ten points in `X_test_processed`. Use `alpha=10` for each model.\n",
    "\n",
    "        Level Up: Make a second scatterplot that compares the predictions on the same data\n",
    "        points between ElasticNet(l1_ratio=1) and Lasso()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary> Answer\n",
    "    </summary>\n",
    "    <code>fig, ax = plt.subplots()\n",
    "enet_r = ElasticNet(alpha=10, l1_ratio=0.01, random_state=42)\n",
    "enet_r.fit(X_train_processed, y_train)\n",
    "preds_enr = enet_r.predict(X_test_processed[:10])\n",
    "preds_ridge = ridge.predict(X_test_processed[:10])\n",
    "ax.scatter(np.arange(10), preds_enr)\n",
    "ax.scatter(np.arange(10), preds_ridge);</code>  \n",
    "        </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>\n",
    "        Level Up\n",
    "    </summary>\n",
    "<code>fig, ax = plt.subplots()\n",
    "enet_l = ElasticNet(alpha=10, l1_ratio=1, random_state=42)\n",
    "enet_l.fit(X_train_processed, y_train)\n",
    "preds_enl = enet_l.predict(X_test_processed[:10])\n",
    "preds_lasso = lasso.predict(X_test_processed[:10])\n",
    "ax.scatter(np.arange(10), preds_enl)\n",
    "ax.scatter(np.arange(10), preds_lasso);</code>\n",
    "    </details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Fitting Regularized Models with Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our friend `sklearn` also includes tools that fit regularized regressions *with cross-validation*: `LassoCV`, `RidgeCV`, and `ElasticNetCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Exercise**: Use `RidgeCV` to fit a seven-fold cross-validated ridge regression model to our `X_train_processed` data and then calculate $R^2$ and the RMSE (root-mean-squared error) on our test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>\n",
    "        Answer\n",
    "    </summary>\n",
    "    <code>rcv = RidgeCV(cv=7)\n",
    "rcv.fit(X_train_processed, y_train)\n",
    "rcv.score(X_test_processed, y_test)\n",
    "np.sqrt(mean_squared_error(y_test, rcv.predict(X_test_processed)))</code>\n",
    "    </details>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "47px",
    "left": "46px",
    "top": "175px",
    "width": "286px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.854px",
    "left": "1039px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
